{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14408043,"sourceType":"datasetVersion","datasetId":9201887}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Execution Checklist Notebook\n\n**Project:** Fine-Tuning LLaMA 3.1-8B-Instruct on Bengali Empathetic Conversations\n**Environment:** Kaggle Free GPU (T4 / P100)\n\n---\n\n## 0. Notebook Metadata (Fill Before Running)\n\n* **Author:** Md Islam\n* **Date:**\n* **GPU Type:**\n* **Strategy Used:** тШР LoRA тШР Unsloth\n* **Model:** LLaMA 3.1-8B-Instruct\n\n---\n\n## 1. Environment Setup\n\n### 1.1 Enable GPU\n\n* [ ] Kaggle Notebook тЖТ Settings тЖТ Accelerator = GPU\n* [ ] Confirm CUDA availability\n\n### 1.2 Install Dependencies\n\n* [ ] transformers\n* [ ] datasets\n* [ ] torch\n* [ ] peft\n* [ ] accelerate\n* [ ] bitsandbytes\n* [ ] evaluate\n* [ ] nltk\n* [ ] rouge-score\n\n### 1.3 Hugging Face Authentication\n\n* [ ] `huggingface-cli login`\n* [ ] Verify access to LLaMA 3.1-8B-Instruct\n\n---\n\n## 2. Dataset Preparation\n\n### 2.1 Load Dataset\n\n* [ ] Load Bengali Empathetic Conversations dataset\n* [ ] Inspect columns and sample records\n\n### 2.2 Data Cleaning\n\n* [ ] Remove null / empty rows\n* [ ] Normalize Bengali Unicode text\n* [ ] Remove duplicates\n\n### 2.3 Instruction Formatting\n\n* [ ] Convert to instructionтАУresponse format\n* [ ] Validate format consistency\n\n### 2.4 Tokenization\n\n* [ ] Load LLaMA tokenizer\n* [ ] Full-sequence tokenization (NO truncation)\n* [ ] Verify maximum token length\n\n### 2.5 Dataset Split\n\n* [ ] Train set\n* [ ] Validation set\n* [ ] Test prompts set\n\n---\n\n## 3. Code Architecture (OOP)\n\n### 3.1 DatasetProcessor\n\n* [ ] Load dataset\n* [ ] Clean data\n* [ ] Instruction formatting\n* [ ] Tokenization\n\n### 3.2 Fine-Tuning Strategy (Strategy Pattern)\n\n* [ ] Define FineTuningStrategy interface\n* [ ] Implement LoRAStrategy\n* [ ] (Optional) Implement UnslothStrategy\n\n---\n\n## 4. Model Training\n\n### 4.1 Model Setup\n\n* [ ] Load LLaMA 3.1-8B-Instruct\n* [ ] Enable gradient checkpointing\n* [ ] Enable mixed precision (fp16 / bf16)\n\n### 4.2 Apply Fine-Tuning Strategy\n\n* [ ] Apply LoRA / Unsloth\n* [ ] Confirm trainable parameters\n\n### 4.3 Training Configuration\n\n* [ ] Batch size\n* [ ] Gradient accumulation\n* [ ] Learning rate\n* [ ] Optimizer (AdamW)\n* [ ] Scheduler\n* [ ] Epoch count\n\n### 4.4 Training Execution\n\n* [ ] Start training\n* [ ] Monitor training loss\n* [ ] Monitor validation loss\n* [ ] Save checkpoints\n\n---\n\n## 5. Experiment Logging\n\n### 5.1 LLAMAExperiments\n\n* [ ] Experiment ID\n* [ ] Model name\n* [ ] Strategy configuration\n* [ ] Train loss\n* [ ] Validation loss\n* [ ] Metrics\n* [ ] Timestamp\n\n### 5.2 GeneratedResponses\n\n* [ ] Experiment ID reference\n* [ ] Input text\n* [ ] Generated response\n* [ ] Timestamp\n\n---\n\n## 6. Evaluation\n\n### 6.1 Automatic Metrics\n\n* [ ] Perplexity\n* [ ] BLEU\n* [ ] ROUGE-1\n* [ ] ROUGE-2\n* [ ] ROUGE-L\n\n### 6.2 Human Evaluation\n\n* [ ] Select 20тАУ50 test prompts\n* [ ] Generate responses\n* [ ] Rate empathy quality\n* [ ] Rate naturalness\n* [ ] Rate relevance\n\n---\n\n## 7. Analysis\n\n* [ ] Compare baseline vs fine-tuned outputs\n* [ ] Identify empathy improvements\n* [ ] Identify failure cases\n* [ ] (Optional) Compare LoRA vs Unsloth\n\n---\n\n## 8. Deliverables\n\n* [ ] Preprocessing notebook/script\n* [ ] Fine-tuning notebook/script\n* [ ] Evaluation notebook/script\n* [ ] Sample Bengali responses\n* [ ] Metrics table\n* [ ] Analysis summary\n* [ ] Documentation (strategy, challenges, solutions)\n\n---\n\n## 9. Final Verification\n\n* [ ] All requirements satisfied\n* [ ] No sequence length reduction\n* [ ] Kaggle GPU limits respected\n* [ ] Code is modular and clean\n* [ ] Submission ready\n\n---\n\n**Status:** тШР In Progress тШР Completed\n","metadata":{}},{"cell_type":"code","source":"import torch\n\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"GPU:\", torch.cuda.get_device_name(0))\nprint(\"Torch version:\", torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:52.030883Z","iopub.execute_input":"2026-01-08T03:05:52.031189Z","iopub.status.idle":"2026-01-08T03:05:55.636965Z","shell.execute_reply.started":"2026-01-08T03:05:52.031162Z","shell.execute_reply":"2026-01-08T03:05:55.636122Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla T4\nTorch version: 2.8.0+cu126\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# now i am going to login to hugging face\n# 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\nfrom huggingface_hub import login\n\nlogin(token=\"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\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:55.638614Z","iopub.execute_input":"2026-01-08T03:05:55.638988Z","iopub.status.idle":"2026-01-08T03:05:56.246412Z","shell.execute_reply.started":"2026-01-08T03:05:55.638957Z","shell.execute_reply":"2026-01-08T03:05:56.245524Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:56.247350Z","iopub.execute_input":"2026-01-08T03:05:56.247630Z","iopub.status.idle":"2026-01-08T03:05:57.631659Z","shell.execute_reply.started":"2026-01-08T03:05:56.247594Z","shell.execute_reply":"2026-01-08T03:05:57.630886Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Replace filename once you see it in Step 2.2\ndf = pd.read_csv(\n    \"/kaggle/input/bengali-empathetic-conversations-corpus/bengali-empathetic-conversations-corpus.csv\"\n)\n\nprint(\"Dataset shape:\", df.shape)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:57.633243Z","iopub.execute_input":"2026-01-08T03:05:57.633604Z","iopub.status.idle":"2026-01-08T03:05:58.112301Z","shell.execute_reply.started":"2026-01-08T03:05:57.633580Z","shell.execute_reply":"2026-01-08T03:05:58.111567Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (38233, 4)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                             Topics  \\\n0                ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм   \n1        ржкржжрж╛рж░рзНржерзЗрж░ ржЕржкржмрзНржпржмрж╣рж╛рж░, ржЖрж╕ржХрзНрждрж┐   \n2                ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм   \n3  ржЖржЪрж░ржгржЧржд ржкрж░рж┐ржмрж░рзНрждржи, рж╕рж╛ржорж╛ржЬрж┐ржХ рж╕ржорзНржкрж░рзНржХ   \n4                        ржжрзБрж╢рзНржЪрж┐ржирзНрждрж╛   \n\n                                   Question-Title  \\\n0              ржорж╛ ржУ рж╕рзНрждрзНрж░рзАрж░ ржоржзрзНржпрзЗ ржорждрж╛ржирзИржХрзНржп ржмрзГржжрзНржзрж┐   \n1      ржЖржорж┐ ржзрзВржоржкрж╛ржирзЗ ржЖрж╕ржХрзНрждред ржЖржорж┐ ржХрж┐ржнрж╛ржмрзЗ ржерж╛ржорж╛рждрзЗ ржкрж╛рж░рж┐?   \n2                ржЖржорж╛рж░ ржкрж░рж┐ржмрж╛рж░рзЗрж░ ржХрж╛ржЫ ржерзЗржХрзЗ ржЧрзЛржкржи рж░рж╛ржЦрж╛   \n3                 ржЕржзрж┐ржХрж╛рж░рзА рж╣ржУржпрж╝рж╛рж░ ржЕржирзНрждрж░рзНржирж┐рж╣рж┐ржд ржХрж╛рж░ржг   \n4  ржЖржорж┐ ржХрж┐ ржУрж╖рзБржз ржЫрж╛ржбрж╝рж╛ ржЙржжрзНржмрзЗржЧ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг ржХрж░рждрзЗ ржкрж╛рж░рж┐?   \n\n                                           Questions  \\\n0   ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржЯрж╛ржиржЯрж╛ржи ржорждржмрж┐рж░рзЛржз ржЪ...   \n1   ржЖржорж┐ ржмрж╛ржЪрзНржЪрж╛ ржирзЗржУржпрж╝рж╛рж░ ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржХрж░ржЫрж┐, рждрж╛ржЗ ржЖржорж╛ржХрзЗ ...   \n2   ржЖржорж╛рж░ ржоржирзЗрж░ ржоржзрзНржпрзЗ ржЧрзЛржкржи ржЖржЫрзЗ, ржПржмржВ ржЖржорж┐ ржЬрж╛ржирж┐ ржирж╛ рждрж╛ржж...   \n3  ржЖржорж┐ ржЖржорж╛рж░ рж╕ржорзНржкрж░рзНржХрзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржЕрждрзНржпржирзНржд ржЕржзрж┐ржХрж╛рж░рж╕рзВржЪржХ...   \n4  ржХржпрж╝рзЗржХ ржмржЫрж░ ржЖржЧрзЗ ржЖржорж╛рж░ ржорж╛ржерж╛ржпрж╝ ржЖржШрж╛ржд рж▓рзЗржЧрзЗржЫрж┐рж▓ ржПржмржВ ржЖржорж╛...   \n\n                                             Answers  \n0   ржЖржкржирж┐ ржпрж╛ ржмрж░рзНржгржирж╛ ржХрж░ржЫрзЗржи рждрж╛ржХрзЗ ржоржирзЛржмрж┐ржЬрзНржЮрж╛ржирзАрж░рж╛ \"рждрзНрж░рж┐...  \n1   рж╣рж╛ржЗред ржЖржкржирж╛рж░ рж╢рж┐рж╢рзБрж░ (ржПржмржВ ржирж┐ржЬрзЗрж░) ржЬржирзНржп ржпрж╛ рж╕рзНржмрж╛рж╕рзНржерзН...  \n2   ржоржирзЗ рж╣ржЪрзНржЫрзЗ ржЧрзЛржкржи рж░рж╛ржЦрж╛ ржПржЦржи ржЖржкржирж╛рж░ ржЬржирзНржп ржПржХржЯрж┐ рж╕ржорж╕рзНржп...  \n3   рж╣рзНржпрж╛рж▓рзЛред ржПржЯрж╛ ржжрзБрж░рзНржжрж╛ржирзНржд ржпрзЗ ржЖржкржирж┐ ржЙржкрж▓ржмрзНржзрж┐ ржХрж░рждрзЗ рж╕ржХ...  \n4   ржЖржкржирж┐ ржмрж▓рзЗржиржирж┐ ржХрж┐ ржмрж╛ ржХржд ржУрж╖рзБржз ржЖржкржирж┐ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзЗржЫрзЗржиред...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topics</th>\n      <th>Question-Title</th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм</td>\n      <td>ржорж╛ ржУ рж╕рзНрждрзНрж░рзАрж░ ржоржзрзНржпрзЗ ржорждрж╛ржирзИржХрзНржп ржмрзГржжрзНржзрж┐</td>\n      <td>ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржЯрж╛ржиржЯрж╛ржи ржорждржмрж┐рж░рзЛржз ржЪ...</td>\n      <td>ржЖржкржирж┐ ржпрж╛ ржмрж░рзНржгржирж╛ ржХрж░ржЫрзЗржи рждрж╛ржХрзЗ ржоржирзЛржмрж┐ржЬрзНржЮрж╛ржирзАрж░рж╛ \"рждрзНрж░рж┐...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ржкржжрж╛рж░рзНржерзЗрж░ ржЕржкржмрзНржпржмрж╣рж╛рж░, ржЖрж╕ржХрзНрждрж┐</td>\n      <td>ржЖржорж┐ ржзрзВржоржкрж╛ржирзЗ ржЖрж╕ржХрзНрждред ржЖржорж┐ ржХрж┐ржнрж╛ржмрзЗ ржерж╛ржорж╛рждрзЗ ржкрж╛рж░рж┐?</td>\n      <td>ржЖржорж┐ ржмрж╛ржЪрзНржЪрж╛ ржирзЗржУржпрж╝рж╛рж░ ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржХрж░ржЫрж┐, рждрж╛ржЗ ржЖржорж╛ржХрзЗ ...</td>\n      <td>рж╣рж╛ржЗред ржЖржкржирж╛рж░ рж╢рж┐рж╢рзБрж░ (ржПржмржВ ржирж┐ржЬрзЗрж░) ржЬржирзНржп ржпрж╛ рж╕рзНржмрж╛рж╕рзНржерзН...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм</td>\n      <td>ржЖржорж╛рж░ ржкрж░рж┐ржмрж╛рж░рзЗрж░ ржХрж╛ржЫ ржерзЗржХрзЗ ржЧрзЛржкржи рж░рж╛ржЦрж╛</td>\n      <td>ржЖржорж╛рж░ ржоржирзЗрж░ ржоржзрзНржпрзЗ ржЧрзЛржкржи ржЖржЫрзЗ, ржПржмржВ ржЖржорж┐ ржЬрж╛ржирж┐ ржирж╛ рждрж╛ржж...</td>\n      <td>ржоржирзЗ рж╣ржЪрзНржЫрзЗ ржЧрзЛржкржи рж░рж╛ржЦрж╛ ржПржЦржи ржЖржкржирж╛рж░ ржЬржирзНржп ржПржХржЯрж┐ рж╕ржорж╕рзНржп...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ржЖржЪрж░ржгржЧржд ржкрж░рж┐ржмрж░рзНрждржи, рж╕рж╛ржорж╛ржЬрж┐ржХ рж╕ржорзНржкрж░рзНржХ</td>\n      <td>ржЕржзрж┐ржХрж╛рж░рзА рж╣ржУржпрж╝рж╛рж░ ржЕржирзНрждрж░рзНржирж┐рж╣рж┐ржд ржХрж╛рж░ржг</td>\n      <td>ржЖржорж┐ ржЖржорж╛рж░ рж╕ржорзНржкрж░рзНржХрзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржЕрждрзНржпржирзНржд ржЕржзрж┐ржХрж╛рж░рж╕рзВржЪржХ...</td>\n      <td>рж╣рзНржпрж╛рж▓рзЛред ржПржЯрж╛ ржжрзБрж░рзНржжрж╛ржирзНржд ржпрзЗ ржЖржкржирж┐ ржЙржкрж▓ржмрзНржзрж┐ ржХрж░рждрзЗ рж╕ржХ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ржжрзБрж╢рзНржЪрж┐ржирзНрждрж╛</td>\n      <td>ржЖржорж┐ ржХрж┐ ржУрж╖рзБржз ржЫрж╛ржбрж╝рж╛ ржЙржжрзНржмрзЗржЧ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг ржХрж░рждрзЗ ржкрж╛рж░рж┐?</td>\n      <td>ржХржпрж╝рзЗржХ ржмржЫрж░ ржЖржЧрзЗ ржЖржорж╛рж░ ржорж╛ржерж╛ржпрж╝ ржЖржШрж╛ржд рж▓рзЗржЧрзЗржЫрж┐рж▓ ржПржмржВ ржЖржорж╛...</td>\n      <td>ржЖржкржирж┐ ржмрж▓рзЗржиржирж┐ ржХрж┐ ржмрж╛ ржХржд ржУрж╖рзБржз ржЖржкржирж┐ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзЗржЫрзЗржиред...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.113352Z","iopub.execute_input":"2026-01-08T03:05:58.113664Z","iopub.status.idle":"2026-01-08T03:05:58.138343Z","shell.execute_reply.started":"2026-01-08T03:05:58.113632Z","shell.execute_reply":"2026-01-08T03:05:58.137474Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 38233 entries, 0 to 38232\nData columns (total 4 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   Topics          38222 non-null  object\n 1   Question-Title  37639 non-null  object\n 2   Questions       38215 non-null  object\n 3   Answers         38228 non-null  object\ndtypes: object(4)\nmemory usage: 1.2+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df.sample(5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.139513Z","iopub.execute_input":"2026-01-08T03:05:58.139977Z","iopub.status.idle":"2026-01-08T03:05:58.155381Z","shell.execute_reply.started":"2026-01-08T03:05:58.139951Z","shell.execute_reply":"2026-01-08T03:05:58.154719Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           Topics                                     Question-Title  \\\n26511     ржХрзНрж╖рж┐ржкрзНржд                                      ржорж╛ржирзБрж╖ ржХрзНрж▓рж╛ржирзНржд   \n8468   ржЖржиржирзНржжржжрж╛ржпрж╝ржХ                                     ржХрж╛ржЬ ржХрж░рждрзЗ ржжрж╛рж░рзБржг   \n1577         PTSD  ржкрж╛рж░рзНрж╢рзНржм ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕рждрзНржпрж┐ржЗ ржЦрж╛рж░рж╛ржк ржПржмржВ ржпрзМржи ржкрзНрж░ржн...   \n10989     ржжрзБржГржЦржЬржиржХ                                рждрж╛ржжрзЗрж░ ржЬрзАржмржи ржирж╖рзНржЯ ржХрж░рзЗ   \n19471    ржЙрждрзНрждрзЗржЬрж┐ржд                                      ржЧрж┐рж▓рзНржб ржкржпрж╝рзЗржирзНржЯ   \n\n                                               Questions  \\\n26511          ржкрж╛рж╢рзЗрж░ рж░рж╛рж╕рзНрждрж╛ржпрж╝ рзлрзж-рзмрзж ржЬржи рж▓рзЛржХ ржпрзЗрждрзЗ ржХрзНрж▓рж╛ржирзНрждред   \n8468    ржЖржорж┐ржУ рждрж╛ржЗ ржХрж░рзЗржЫрж┐ред ржмрж╛ржЪрзНржЪрж╛ржжрзЗрж░ рж╕рж╛ржерзЗржУ ржХрж╛ржЬ ржХрж░рж╛ ржЦрзБржм ржнрж╛рж▓рзЛ   \n1577    ржЖржорж╛рж░ PTSD ржЖржЫрзЗред ржкрж╛рж░рзНрж╢рзНржм ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕рждрзНржпрж┐ржЗ ржЦрж╛...   \n10989  рж╣рзНржпрж╛ржБ...ржПржЯрж╛ ржЦрзБржмржЗ ржжрзБржГржЦржЬржиржХ ржмрж┐рж╢рзЗрж╖ ржХрж░рзЗ ржпржЦржи ржЖржкржирж┐ ржЬрж╛...   \n19471  ржЖржорж┐ ржЖржорж╛рж░ ржЧрж┐рж▓рзНржб ржкржпрж╝рзЗржирзНржЯ ржорзЗржЗрж▓рзЗ ржЖрж╕рж╛рж░ ржЬржирзНржп ржЕржкрзЗржХрзНрж╖рж╛...   \n\n                                                 Answers  \n26511                     ржХржд ржжрзНрж░рзБржд рждрж╛рж░рж╛ ржпрзЗрждрзЗ ржЕржирзБржорж┐ржд рж╣ржпрж╝?  \n8468   рж╣рзНржпрж╛ржБ, ржмрж╛ржЪрзНржЪрж╛ржжрзЗрж░ рж╢рзЗржЦрж╛ржирзЛ ржПржмржВ ржХрзАржнрж╛ржмрзЗ ржХрж╛рж░рзНржпржХрж░ ржорж╛ржи...  \n1577    ржзрзАрж░рзЗ ржзрзАрж░рзЗ ржпрзЗ рж╣рж╛рж░рзЗ ржЖржкржирж┐ ржЖржкржирж╛рж░ ржЬрзАржмржи ржлрж┐рж░рзЗ ржкрж╛ржмрзЗржиред...  \n10989                     ржЖржкржирж╛ржХрзЗ ржПржЗ рж▓рзЛржХржжрзЗрж░ ржпрзЗрждрзЗ ржжрж┐рждрзЗ рж╣ржмрзЗ  \n19471                    ржЧрж┐рж▓рзНржб рж╕ржжрж╕рзНржпржжрзЗрж░ ржЬржирзНржп ржкржпрж╝рзЗржирзНржЯ ржХрж┐?  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topics</th>\n      <th>Question-Title</th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26511</th>\n      <td>ржХрзНрж╖рж┐ржкрзНржд</td>\n      <td>ржорж╛ржирзБрж╖ ржХрзНрж▓рж╛ржирзНржд</td>\n      <td>ржкрж╛рж╢рзЗрж░ рж░рж╛рж╕рзНрждрж╛ржпрж╝ рзлрзж-рзмрзж ржЬржи рж▓рзЛржХ ржпрзЗрждрзЗ ржХрзНрж▓рж╛ржирзНрждред</td>\n      <td>ржХржд ржжрзНрж░рзБржд рждрж╛рж░рж╛ ржпрзЗрждрзЗ ржЕржирзБржорж┐ржд рж╣ржпрж╝?</td>\n    </tr>\n    <tr>\n      <th>8468</th>\n      <td>ржЖржиржирзНржжржжрж╛ржпрж╝ржХ</td>\n      <td>ржХрж╛ржЬ ржХрж░рждрзЗ ржжрж╛рж░рзБржг</td>\n      <td>ржЖржорж┐ржУ рждрж╛ржЗ ржХрж░рзЗржЫрж┐ред ржмрж╛ржЪрзНржЪрж╛ржжрзЗрж░ рж╕рж╛ржерзЗржУ ржХрж╛ржЬ ржХрж░рж╛ ржЦрзБржм ржнрж╛рж▓рзЛ</td>\n      <td>рж╣рзНржпрж╛ржБ, ржмрж╛ржЪрзНржЪрж╛ржжрзЗрж░ рж╢рзЗржЦрж╛ржирзЛ ржПржмржВ ржХрзАржнрж╛ржмрзЗ ржХрж╛рж░рзНржпржХрж░ ржорж╛ржи...</td>\n    </tr>\n    <tr>\n      <th>1577</th>\n      <td>PTSD</td>\n      <td>ржкрж╛рж░рзНрж╢рзНржм ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕рждрзНржпрж┐ржЗ ржЦрж╛рж░рж╛ржк ржПржмржВ ржпрзМржи ржкрзНрж░ржн...</td>\n      <td>ржЖржорж╛рж░ PTSD ржЖржЫрзЗред ржкрж╛рж░рзНрж╢рзНржм ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕рждрзНржпрж┐ржЗ ржЦрж╛...</td>\n      <td>ржзрзАрж░рзЗ ржзрзАрж░рзЗ ржпрзЗ рж╣рж╛рж░рзЗ ржЖржкржирж┐ ржЖржкржирж╛рж░ ржЬрзАржмржи ржлрж┐рж░рзЗ ржкрж╛ржмрзЗржиред...</td>\n    </tr>\n    <tr>\n      <th>10989</th>\n      <td>ржжрзБржГржЦржЬржиржХ</td>\n      <td>рждрж╛ржжрзЗрж░ ржЬрзАржмржи ржирж╖рзНржЯ ржХрж░рзЗ</td>\n      <td>рж╣рзНржпрж╛ржБ...ржПржЯрж╛ ржЦрзБржмржЗ ржжрзБржГржЦржЬржиржХ ржмрж┐рж╢рзЗрж╖ ржХрж░рзЗ ржпржЦржи ржЖржкржирж┐ ржЬрж╛...</td>\n      <td>ржЖржкржирж╛ржХрзЗ ржПржЗ рж▓рзЛржХржжрзЗрж░ ржпрзЗрждрзЗ ржжрж┐рждрзЗ рж╣ржмрзЗ</td>\n    </tr>\n    <tr>\n      <th>19471</th>\n      <td>ржЙрждрзНрждрзЗржЬрж┐ржд</td>\n      <td>ржЧрж┐рж▓рзНржб ржкржпрж╝рзЗржирзНржЯ</td>\n      <td>ржЖржорж┐ ржЖржорж╛рж░ ржЧрж┐рж▓рзНржб ржкржпрж╝рзЗржирзНржЯ ржорзЗржЗрж▓рзЗ ржЖрж╕рж╛рж░ ржЬржирзНржп ржЕржкрзЗржХрзНрж╖рж╛...</td>\n      <td>ржЧрж┐рж▓рзНржб рж╕ржжрж╕рзНржпржжрзЗрж░ ржЬржирзНржп ржкржпрж╝рзЗржирзНржЯ ржХрж┐?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"print(df.iloc[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.156230Z","iopub.execute_input":"2026-01-08T03:05:58.156476Z","iopub.status.idle":"2026-01-08T03:05:58.167023Z","shell.execute_reply.started":"2026-01-08T03:05:58.156442Z","shell.execute_reply":"2026-01-08T03:05:58.166377Z"}},"outputs":[{"name":"stdout","text":"Topics                                           ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм\nQuestion-Title                   ржорж╛ ржУ рж╕рзНрждрзНрж░рзАрж░ ржоржзрзНржпрзЗ ржорждрж╛ржирзИржХрзНржп ржмрзГржжрзНржзрж┐\nQuestions          ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржЯрж╛ржиржЯрж╛ржи ржорждржмрж┐рж░рзЛржз ржЪ...\nAnswers            ржЖржкржирж┐ ржпрж╛ ржмрж░рзНржгржирж╛ ржХрж░ржЫрзЗржи рждрж╛ржХрзЗ ржоржирзЛржмрж┐ржЬрзНржЮрж╛ржирзАрж░рж╛ \"рждрзНрж░рж┐...\nName: 0, dtype: object\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# now I am going to check the quality of the dataset\n# Check missing values\nprint(df.isnull().sum())\n\n# Check duplicates\nprint(\"Duplicate rows:\", df.duplicated().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.167878Z","iopub.execute_input":"2026-01-08T03:05:58.168250Z","iopub.status.idle":"2026-01-08T03:05:58.217317Z","shell.execute_reply.started":"2026-01-08T03:05:58.168218Z","shell.execute_reply":"2026-01-08T03:05:58.216726Z"}},"outputs":[{"name":"stdout","text":"Topics             11\nQuestion-Title    594\nQuestions          18\nAnswers             5\ndtype: int64\nDuplicate rows: 25\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.218259Z","iopub.execute_input":"2026-01-08T03:05:58.218495Z","iopub.status.idle":"2026-01-08T03:05:58.223443Z","shell.execute_reply.started":"2026-01-08T03:05:58.218472Z","shell.execute_reply":"2026-01-08T03:05:58.222795Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Topics', 'Question-Title', 'Questions', 'Answers'], dtype='object')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df = df[[\"Topics\", \"Questions\", \"Answers\"]]\nprint(df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.226083Z","iopub.execute_input":"2026-01-08T03:05:58.226397Z","iopub.status.idle":"2026-01-08T03:05:58.239755Z","shell.execute_reply.started":"2026-01-08T03:05:58.226374Z","shell.execute_reply":"2026-01-08T03:05:58.238903Z"}},"outputs":[{"name":"stdout","text":"(38233, 3)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"df = df.dropna(subset=[\"Questions\", \"Answers\"])\n\ndf = df[\n    (df[\"Questions\"].str.strip() != \"\") &\n    (df[\"Answers\"].str.strip() != \"\")\n]\n\ndf = df.reset_index(drop=True)\n\nprint(\"Cleaned dataset shape:\", df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.240719Z","iopub.execute_input":"2026-01-08T03:05:58.241036Z","iopub.status.idle":"2026-01-08T03:05:58.286766Z","shell.execute_reply.started":"2026-01-08T03:05:58.240995Z","shell.execute_reply":"2026-01-08T03:05:58.285960Z"}},"outputs":[{"name":"stdout","text":"Cleaned dataset shape: (38210, 3)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def normalize_text(text: str) -> str:\n    text = text.strip()\n    text = \" \".join(text.split())  # normalize whitespace\n    return text\n\ndf[\"Questions\"] = df[\"Questions\"].apply(normalize_text)\ndf[\"Answers\"] = df[\"Answers\"].apply(normalize_text)\ndf[\"Topics\"] = df[\"Topics\"].fillna(\"\").apply(normalize_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.287737Z","iopub.execute_input":"2026-01-08T03:05:58.287983Z","iopub.status.idle":"2026-01-08T03:05:58.486010Z","shell.execute_reply.started":"2026-01-08T03:05:58.287959Z","shell.execute_reply":"2026-01-08T03:05:58.485410Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Instruction:\nRespond empathetically in Bengali to the following message.\n\n### Context:\nTopic: {topic}\n\n### User:\n{question}\n\n### Assistant:\n{answer}","metadata":{}},{"cell_type":"code","source":"def format_instruction(row):\n    return f\"\"\"### Instruction:\nRespond empathetically in Bengali to the following message.\n\n### Context:\nTopic: {row['Topics']}\n\n### User:\n{row['Questions']}\n\n### Assistant:\n{row['Answers']}\"\"\"\n\ndf[\"text\"] = df.apply(format_instruction, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.486836Z","iopub.execute_input":"2026-01-08T03:05:58.487161Z","iopub.status.idle":"2026-01-08T03:05:58.802679Z","shell.execute_reply.started":"2026-01-08T03:05:58.487107Z","shell.execute_reply":"2026-01-08T03:05:58.802066Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(df[\"text\"].iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.803528Z","iopub.execute_input":"2026-01-08T03:05:58.803841Z","iopub.status.idle":"2026-01-08T03:05:58.809380Z","shell.execute_reply.started":"2026-01-08T03:05:58.803802Z","shell.execute_reply":"2026-01-08T03:05:58.808794Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nRespond empathetically in Bengali to the following message.\n\n### Context:\nTopic: ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржжрзНржмржирзНржжрзНржм\n\n### User:\nржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржЯрж╛ржиржЯрж╛ржи ржорждржмрж┐рж░рзЛржз ржЪрж▓ржЫрзЗред ржЕрждрзАрждрзЗ, рждрж╛ржжрзЗрж░ ржоржзрзНржпрзЗ ржЫрзЛржЯржЦрж╛ржЯрзЛ ржкрж╛рж░рзНржержХрзНржп ржЫрж┐рж▓ред ржЙржжрж╛рж╣рж░ржгрж╕рзНржмрж░рзВржк, ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржЖржорж╛рж░ ржХрж╛ржЫрзЗ ржЕржнрж┐ржпрзЛржЧ ржХрж░ржмрзЗ ржпрзЗ ржЖржорж╛рж░ ржорж╛ ржЦрзБржм ржХрж░рзНрждрзГрждрзНржмржкрзНрж░ржпрж╝рж╛рж╕рзА; ржЖржорж╛рж░ ржорж╛ ржЕржнрж┐ржпрзЛржЧ ржХрж░ржмрзЗржи ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА ржЕрж▓рж╕ред рждржмрзЗ ржЗржжрж╛ржирзАржВ рждрж╛ рждрзАржмрзНрж░рждрж░ рж╣ржпрж╝рзЗржЫрзЗ ред ржЖржорж┐ ржоржирзЗ ржХрж░рж┐, ржПрж░ ржХрж╛рж░ржг рж╣ржЪрзНржЫрзЗ ржЖржорж╛рж░ рж╕рзНрждрзНрж░рзА рждрж╛рж░ рж╕рж╛ржерзЗ ржПржХржмрж╛рж░ ржХржерж╛рж░ ржкрзНрж░рждрж┐рждрзНрждрж░ ржХрж░рзЗржЫрж┐рж▓ред ржПржЦржи, ржпрзЗржХрзЛржирзЛ рж╕рж╛ржорж╛ржирзНржп ржорждржмрж┐рж░рзЛржзржХрзЗ ржмржбрж╝ ржХрж░рж╛ рж╣ржпрж╝, ржпрж╛ ржмржбрж╝ ржорждржмрж┐рж░рзЛржзрзЗрж░ ржжрж┐ржХрзЗ ржкрж░рж┐ржЪрж╛рж▓рж┐ржд ржХрж░рзЗред ржЖржорж┐ ржХрж┐ ржХрж░рждрзЗ ржкрж╛рж░рж┐?\n\n### Assistant:\nржЖржкржирж┐ ржпрж╛ ржмрж░рзНржгржирж╛ ржХрж░ржЫрзЗржи рждрж╛ржХрзЗ ржоржирзЛржмрж┐ржЬрзНржЮрж╛ржирзАрж░рж╛ \"рждрзНрж░рж┐ржнрзБржЬржХрж░ржг\" ржмрж▓рзЗ ржЕржнрж┐рж╣рж┐ржд ржХрж░рзЗржЫрзЗржиред ржпрж╛ рж╣ржпрж╝ ржпржЦржи ржкрж░рж┐ржмрж╛рж░рзЗрж░ ржПржХржЬржи рж╕ржжрж╕рзНржп ржпрж╛рж░ рж╕рж╛ржерзЗ рждрж╛ржжрзЗрж░ рж╕ржорж╕рзНржпрж╛ ржЖржЫрзЗ рждрж╛рж░ рж╕рж╛ржерзЗ ржХржерж╛ ржирж╛ ржмрж▓рзЗ ржПржмржВ ржкрж░рж┐ржмрж░рзНрждрзЗ ржкрж░рж┐ржмрж╛рж░рзЗрж░ рждрзГрждрзАржпрж╝ рж╕ржжрж╕рзНржпрзЗрж░ ржХрж╛ржЫрзЗ ржЕржнрж┐ржпрзЛржЧ ржЬрж╛ржирж╛рждрзЗ ржпрж╛ржпрж╝ред ржЖржкржирж╛ржХрзЗ 'рждрзНрж░рж┐ржнрзБржЬрж╛ржХрж╛рж░' ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ; ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ржпрж╝рзЗрж░ ржжрзНржмрж╛рж░рж╛ред ржПржЯрж┐ ржкрзНрж░рж╛ржпрж╝ржЗ ржкрж░рж┐ржмрж╛рж░ржЧрзБрж▓рж┐рждрзЗ ржжрзЗржЦрж╛ ржпрж╛ржпрж╝ред ржПржЯрж╛ рж╕рж░рзНржмрждрзНрж░ ржжрзЗржЦрж╛ ржпрж╛ржЪрзНржЫрзЗ. ржЖржкржирж┐ ржХрждржмрж╛рж░ ржХрж╛рж░рзЛ рж╕рж╛ржерзЗ рж╕ржорж╕рзНржпрж╛ржпрж╝ ржкржбрж╝рзЗржЫрзЗржи ржХрж┐ржирзНрждрзБ ржЖржкржирж┐ рждрж╛ржжрзЗрж░ ржХрж╛ржЫрзЗ рждрж╛ржжрзЗрж░ ржмрж▓рждрзЗ ржпрж╛ржиржирж┐, ржЖржкржирж┐ ржЕржирзНржп ржХрж╛рж░рзЛ ржХрж╛ржЫрзЗ ржЕржнрж┐ржпрзЛржЧ ржХрж░рждрзЗ ржЧрзЗржЫрзЗржи? ржПржХржЬржи ржмрзНржпржХрзНрждрж┐рж░ ржкржХрзНрж╖рзЗ ржЕржирзНржпрзЗрж░ ржорзБржЦрзЛржорзБржЦрж┐ рж╣ржУржпрж╝рж╛ рж╕рж╛ржзрж╛рж░ржгржд ржХржарж┐ржи, ржмрж┐рж╢рзЗрж╖ржд ржПржоржи рж╕ржорзНржкрж░рзНржХржЧрзБрж▓рж┐рждрзЗ ржпрзЗржЦрж╛ржирзЗ рж╢ржХрзНрждрж┐рж░ ржкрж╛рж░рзНржержХрзНржп рж░ржпрж╝рзЗржЫрзЗред ржЙржжрж╛рж╣рж░ржгрж╕рзНржмрж░рзВржк, ржЖржорж┐ ржмрж╛ржЬрж┐ ржзрж░рждрзЗ ржкрж╛рж░рж┐ ржпрзЗ ржЖржкржирж╛рж░ ржЕржнрж┐ржпрзЛржЧ ржирж┐ржпрж╝рзЗ ржмрж╕рзЗрж░ ржХрж╛ржЫрзЗ ржпрж╛ржУржпрж╝рж╛рж░ ржЪрзЗржпрж╝рзЗ ржЖржкржирж╛рж░ ржмрж╕ рж╕ржорзНржкрж░рзНржХрзЗ ржПржХржЬржи рж╕рж╣ржХрж░рзНржорзАрж░ ржХрж╛ржЫрзЗ ржЕржнрж┐ржпрзЛржЧ ржХрж░рж╛ рж╕рж╣ржЬред ржЖржорж┐ ржмрж▓ржЫрж┐ ржирж╛ ржпрзЗ рждрзНрж░рж┐ржнрзБржЬрж╛ржХрж░ржг рж╕ржмрж╕ржоржпрж╝ ржПржХржЯрж┐ ржЦрж╛рж░рж╛ржк ржЬрж┐ржирж┐рж╕ред ржХржЦржиржУ ржХржЦржиржУ ржПржХржЬржи рждрзГрждрзАржпрж╝ ржкржХрзНрж╖рзЗрж░ ржоржзрзНржпрж╕рзНржерждрж╛ржХрж╛рж░рзАрж░ ржкрзНрж░ржпрж╝рзЛржЬржи рж╣ржпрж╝ ржпрж╛рж░рж╛ ржжрзНржмрж┐ржоржд ржкрзЛрж╖ржг ржХрж░рзЗржи рждрж╛ржжрзЗрж░ ржоржзрзНржпрзЗ рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржирзЗрж░ ржЬржирзНржпред ржпрзЗ ржерзЗрж░рж╛ржкрж┐рж╕рзНржЯ ржкрзНрж░рждрж┐ржжрж┐ржи ржХрж┐! ржХржЦржиржУ ржХржЦржиржУ рж╢рзБржзрзБржорж╛рждрзНрж░ ржЕржирзНржп ржХрж╛рж░ржУ ржжрзГрж╖рзНржЯрж┐ржнржЩрзНржЧрж┐ ржкрж╛ржУржпрж╝рж╛ ржЖржкржирж╛ржХрзЗ рж╕ржорж╕рзНржпрж╛ржЯрж┐ ржЖрж░ржУ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржжрзЗржЦрждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржпрж╛ржЗрж╣рзЛржХ, ржЖржкржирж╛рж░ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рждрзЗ ржПржЯрж┐ ржПржХржЯрж┐ рж╕ржорж╕рзНржпрж╛ рж╣ржпрж╝рзЗ ржЙржаржЫрзЗ ржоржд рж╢рзЛржирж╛ржЪрзНржЫрзЗ. ржЖржкржирж┐ ржжрзБржЬржи рж▓рзЛржХрзЗрж░ ржорж╛ржЭржЦрж╛ржирзЗ ржЖржЯржХрзЗ ржЖржЫрзЗржи ржпрж╛рж░рж╛ ржЖржкржирж╛ржХрзЗ ржнрж╛рж▓ржмрж╛рж╕рзЗржи ржПржмржВ ржЖржкржирж┐ ржнрж╛рж▓ржмрж╛рж╕рзЗржиред рждрж╛ржжрзЗрж░ ржкрж╛рж░рзНржержХрзНржп ржХрж╛ржЬ. рж╕ржорзНржнржмржд ржПржЯрж┐ ржПржХржЯрж┐ рж╕рж╛ржзрж╛рж░ржг ржнрзБрж▓ ржмрзЛржЭрж╛ржмрзБржЭрж┐ ржЫрж┐рж▓ ржпрж╛ ржХрж┐ржЫрзБ ржЦрзЛрж▓рж╛ ржпрзЛржЧрж╛ржпрзЛржЧ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржПржоржиржХрж┐ ржпржжрж┐ рждрж╛рж░рж╛ рж╕рждрзНржпрж┐ржЗ ржПржХрзЗ ржЕржкрж░ржХрзЗ ржкржЫржирзНржж ржирж╛ ржХрж░рзЗ ржПржмржВ ржПржХрж╕рж╛ржерзЗ ржЪрж▓рждрзЗ ржирж╛ ржкрж╛рж░рзЗ, рждржмрзБржУ рждрж╛ржжрзЗрж░ ржЙржнржпрж╝рзЗрж░ рж╕рж╛ржерзЗ ржЖржкржирж╛рж░ рж╕ржорзНржкрж░рзНржХ ржЖрж░ржУ ржЦрж╛рж░рж╛ржк рж╣рждрзЗ ржЪрж▓рзЗржЫрзЗ ржпрждржжрж┐ржи ржЖржкржирж┐ ржорж╛ржЭржЦрж╛ржирзЗ ржЖржЯржХрзЗ ржерж╛ржХржмрзЗржиред ржмрзЛржЭрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи рждрж╛ржжрзЗрж░ ржЖржЪрж░ржгрзЗрж░ ржкрж┐ржЫржирзЗ ржЕржирзБржнрзВрждрж┐ ржХрж┐ рж╣рждрзЗ ржкрж╛рж░рзЗред ржПржЯрж╛ рж╕ржорзНржнржм ржпрзЗ рждрж╛рж░рж╛ ржЙржнржпрж╝ржЗ ржЕржирзНржпрзЗрж░ ржжрзНржмрж╛рж░рж╛ рж╣рзБржоржХрж┐ ржмрзЛржз ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржПрж░рж╛ ржЖржкржирж╛рж░ ржЬрзАржмржирзЗрж░ рж╕ржмржЪрзЗржпрж╝рзЗ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржжрзБржЗ ржирж╛рж░рзА ржПржмржВ рждрж╛рж░рж╛ ржжрзБржЬржирзЗржЗ ржПржЯрж╛ ржЬрж╛ржирзЗред ржЖржкржирж╛рж░ ржорж╛ ржнржпрж╝ ржкрж╛ржЪрзНржЫрзЗржи ржпрзЗ рждрж┐ржирж┐ ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзАрж░ ржорзБржЦрзЛржорзБржЦрж┐ рж╣рж▓рзЗ рждрж┐ржирж┐ ржЖржкржирж╛ржХрзЗ рж╣рж╛рж░рж╛ржмрзЗржиред ржЖржорж┐ рж╢рзБржирзЗржЫрж┐ ржПржХржЬржи рж╢рж╛рж╢рзБржбрж╝рж┐ рждрж╛рж░ ржЫрзЗрж▓рзЗрж░ рж╕рзНрждрзНрж░рзАржХрзЗ рждрж╛рж░ ржЫрзЗрж▓рзЗрж░ ржкрзНрж░ржмрзЗрж╢ржжрзНржмрж╛рж░ рж╣рж┐рж╕рж╛ржмрзЗ ржмрж░рзНржгржирж╛ ржХрж░рзЗржЫрзЗржиред рж╕рзНрждрзНрж░рзА ржХржЦржи ржПржмржВ ржХржд ржШржи ржШржи рждрж╛рж░ ржЫрзЗрж▓рзЗржХрзЗ ржжрзЗржЦрждрзЗ ржкрж╛ржпрж╝ рждрж╛ ржирж┐рж░рзНржзрж╛рж░ржг ржХрж░рж╛рж░ ржХрзНрж╖ржорждрж╛ рж░ржпрж╝рзЗржЫрзЗред рж╕рзНрждрзНрж░рзАржУ ржирж╛рждрж┐-ржирж╛рждржирж┐ржжрзЗрж░ ржкрзНрж░ржмрзЗрж╢ржжрзНржмрж╛рж░ред ржпржжрж┐ ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзА рждрж╛рж░ рж╢рж╛рж╢рзБржбрж╝рж┐ржХрзЗ ржкржЫржирзНржж ржирж╛ ржХрж░рзЗржи рждржмрзЗ рждрж┐ржирж┐ ржЖржкржирж╛рж░ ржПржмржВ ржЖржкржирж╛рж░ ржжрзБржЬржирзЗрж░ рж╕ржирзНрждрж╛ржирзЗрж░ рж╕рж╛ржерзЗ рждрж╛рж░ рж╢рж╛рж╢рзБржбрж╝рж┐рж░ рж╕ржорзНржкрж░рзНржХржХрзЗ ржорж╛рж░рж╛рждрзНржоржХржнрж╛ржмрзЗ ржмрж╛ржзрж╛ ржмрж╛ ржХрзНрж╖рждрж┐ ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзАрж░ ржжрзГрж╖рзНржЯрж┐ржХрзЛржг ржерзЗржХрзЗ, ржПржЯрж┐ рж╕рзЗржЗ ржорж╣рж┐рж▓рж╛ ржпрж╛ рждрж╛рж░ ржоржирзЗ рж╣рждрзЗ ржкрж╛рж░рзЗ рж╕рзЗ ржХржЦржиржЗ ржмрж╛ржБржЪрждрзЗ ржкрж╛рж░ржмрзЗ ржирж╛ред ржЖржкржирж┐ ржпржжрж┐ ржирж┐ржпрж╝ржорж┐ржд ржЖржкржирж╛рж░ ржорж╛ржпрж╝рзЗрж░ рж░рж╛ржирзНржирж╛, рждрж╛рж░ ржмрж╛ржбрж╝рж┐рж░ ржХрж╛ржЬ, ржмрж╛ржЧрж╛ржи ржмрж╛ ржЕржирзНржп ржХрж┐ржЫрзБрж░ ржкрзНрж░рж╢ржВрж╕рж╛ ржХрж░рзЗржи рждржмрзЗ ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзА ржоржирзЗ ржХрж░рждрзЗ ржкрж╛рж░рзЗржи ржпрзЗ ржЖржкржирж┐ ржПржЗ ржХрзНрж╖рзЗрждрзНрж░рзЗ рждрж╛рж░ ржирж┐ржЬрзЗрж░ ржкрзНрж░ржЪрзЗрж╖рзНржЯрж╛ржХрзЗ рж╣рзНрж░рж╛рж╕ ржХрж░ржЫрзЗржи ржПржмржВ ржЕржкрзНрж░рж╢ржВрж╕рж┐ржд ржмрзЛржз ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред ржПржЯрж┐ ржмрж┐рж╢рзЗрж╖ржд ржХржарж┐ржи рж╣рждрзЗ ржкрж╛рж░рзЗ ржпржжрж┐ ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржорж╛ ржПржХржЗ рж░ржХржо ржирж╛ рж╣ржпрж╝ред ржЖржорж┐ ржмрж▓ржЫрж┐ ржирж╛ ржпрзЗ ржЖржкржирж╛рж░ ржкрж░рж┐ржмрж╛рж░рзЗрж░ ржЕржмрж╕рзНржерж╛ ржПржоржиред ржПржЧрзБрж▓рж┐ ржЖржкржирж╛рж░ ржорждрзЛ ржПржХржЗ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рждрзЗ ржЕржирзНржпрж╛ржирзНржп ржкрж░рж┐ржмрж╛рж░рзЗрж░ ржерзЗржХрзЗ ржХржпрж╝рзЗржХржЯрж┐ ржЙржжрж╛рж╣рж░ржгред ржЖржкржирж╛рж░ рж╕рж╛ржерзЗ ржпржЦржи ржЖржкржирж┐ рждрж╛ржжрзЗрж░ рж╕рж╛ржерзЗ ржПржХржоржд ржиржиред ржЖржкржирж┐ ржЕржирзНржпрзЗрж░ ржмрж┐рж░рзБржжрзНржзрзЗ рждрж╛ржжрзЗрж░ рж╕рж╛ржерзЗ ржирж┐ржЬрзЗржХрзЗ рж╕рж╛рж░рж┐ржмржжрзНржз ржирж╛ ржХрж░рж▓рзЗ рждрж╛рж░рж╛ ржмрж┐рж░ржХрзНржд рж╣ржмрзЗред рждрж╛рж░рж╛ ржХрзНрж╖рзБржмрзНржз рж╣ржмрзЗ ржпржЦржи ржоржирзЗ рж╣ржмрзЗ ржЖржкржирж┐ ржЕржирзНржпрзЗрж░ ржкржХрзНрж╖ ржмрзЗржЫрзЗ ржирж┐ржЪрзНржЫрзЗржи ржмрж╛ ржЖржкржирж┐ рждрж╛ржжрзЗрж░ ржкржХрзНрж╖рзЗ ржжрж╛ржБржбрж╝рж╛ржЪрзНржЫрзЗржи ржирж╛ ржпрзЗржоржи рждрж╛рж░рж╛ ржоржирзЗ ржХрж░рзЗ ржЖржкржирж╛рж░ ржЙржЪрж┐рждред рж╕ржмржЪрзЗржпрж╝рзЗ ржЦрж╛рж░рж╛ржк ржХрзНрж╖рзЗрждрзНрж░рзЗ, ржпржжрж┐ ржПржЯрж┐ ржХрзНрж░ржоржмрж░рзНржзржорж╛ржи рж╣рждрзЗ ржерж╛ржХрзЗ рждржмрзЗ ржЖржкржирж┐ ржПржоржиржХрж┐ ржЖржкржирж╛рж░ рж╕рзНрждрзНрж░рзА ржПржмржВ ржЖржкржирж╛рж░ ржорж╛ржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржмрзЗржЫрзЗ ржирзЗржУржпрж╝рж╛рж░ ржЕрж╕ржорзНржнржм ржЕржмрж╕рзНржерж╛ржирзЗ ржирж┐ржЬрзЗржХрзЗ ржЦрзБржБржЬрзЗ ржкрзЗрждрзЗ ржкрж╛рж░рзЗржи ржпрж╛рж░ ржЕрж░рзНрже рж╣рждрзЗ ржкрж╛рж░рзЗ ржЕржирзНржпрзЗрж░ рж╕рж╛ржерзЗ ржпрзЛржЧрж╛ржпрзЛржЧ ржЫрж┐ржирзНржи ржХрж░рж╛, рж╕рзЗржЗ рж╕ржорзНржкрж░рзНржХржЯрж┐ рж╢рзЗрж╖ ржХрж░рж╛ред ржЖрж░ржУ рж╕рж░рзНржкрж┐рж▓ рж╣ржУржпрж╝рж╛рж░ ржЖржЧрзЗ ржЧрждрж┐рж╢рзАрж▓рждрж╛ ржкрж░рж┐ржмрж░рзНрждржи ржХрж░рзБржиред\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(\n    df,\n    test_size=0.1,\n    random_state=42\n)\n\nprint(\"Train size:\", len(train_df))\nprint(\"Validation size:\", len(val_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:58.810286Z","iopub.execute_input":"2026-01-08T03:05:58.810551Z","iopub.status.idle":"2026-01-08T03:05:59.507272Z","shell.execute_reply.started":"2026-01-08T03:05:58.810528Z","shell.execute_reply":"2026-01-08T03:05:59.506602Z"}},"outputs":[{"name":"stdout","text":"Train size: 34389\nValidation size: 3821\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\n    MODEL_NAME,\n    use_fast=True\n)\n\n# LLaMA requires explicit padding token\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:05:59.508283Z","iopub.execute_input":"2026-01-08T03:05:59.508816Z","iopub.status.idle":"2026-01-08T03:06:07.964011Z","shell.execute_reply.started":"2026-01-08T03:05:59.508788Z","shell.execute_reply":"2026-01-08T03:06:07.963174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d140b08b9e36447e8f2cf6b5a0098c41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b3475fb7d146d193babd84a08f6247"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de08c008a6354ea085e482aeda7b92e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6876325738d34ed29db5130ec67b5f41"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df[[\"text\"]])\nval_dataset   = Dataset.from_pandas(val_df[[\"text\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:07.965018Z","iopub.execute_input":"2026-01-08T03:06:07.965602Z","iopub.status.idle":"2026-01-08T03:06:08.204863Z","shell.execute_reply.started":"2026-01-08T03:06:07.965574Z","shell.execute_reply":"2026-01-08T03:06:08.204279Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"MAX_LEN = 512   # ЁЯФС critical\n\ndef tokenize_function(examples):\n    outputs = tokenizer(\n        examples[\"text\"],\n        truncation=True,        # тЬЕ now allowed\n        max_length=MAX_LEN,\n        padding=False,\n        return_attention_mask=True,\n    )\n    outputs[\"labels\"] = outputs[\"input_ids\"].copy()\n    return outputs\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:08.205846Z","iopub.execute_input":"2026-01-08T03:06:08.206238Z","iopub.status.idle":"2026-01-08T03:06:08.210914Z","shell.execute_reply.started":"2026-01-08T03:06:08.206207Z","shell.execute_reply":"2026-01-08T03:06:08.210354Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"tokenized_train = train_dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"text\"]\n)\n\ntokenized_val = val_dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"text\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:08.211849Z","iopub.execute_input":"2026-01-08T03:06:08.212090Z","iopub.status.idle":"2026-01-08T03:06:16.843888Z","shell.execute_reply.started":"2026-01-08T03:06:08.212059Z","shell.execute_reply":"2026-01-08T03:06:16.843240Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/34389 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911adea699634d469b6a6f7fa8702ab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb93a17c0054e509ab7b14df29a4324"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"lengths = [len(x) for x in tokenized_train[\"input_ids\"]]\n\nprint(\"Max tokens:\", max(lengths))\nprint(\"Average tokens:\", sum(lengths) // len(lengths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:16.844873Z","iopub.execute_input":"2026-01-08T03:06:16.845186Z","iopub.status.idle":"2026-01-08T03:06:20.551349Z","shell.execute_reply.started":"2026-01-08T03:06:16.845152Z","shell.execute_reply":"2026-01-08T03:06:20.550570Z"}},"outputs":[{"name":"stdout","text":"Max tokens: 512\nAverage tokens: 240\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"sample = tokenized_train[0]\nprint(\"Input IDs length:\", len(sample[\"input_ids\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:20.552227Z","iopub.execute_input":"2026-01-08T03:06:20.552530Z","iopub.status.idle":"2026-01-08T03:06:20.557513Z","shell.execute_reply.started":"2026-01-08T03:06:20.552495Z","shell.execute_reply":"2026-01-08T03:06:20.556711Z"}},"outputs":[{"name":"stdout","text":"Input IDs length: 167\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**Step 5**","metadata":{}},{"cell_type":"code","source":"from abc import ABC, abstractmethod\n\nclass FineTuningStrategy(ABC):\n\n    @abstractmethod\n    def apply(self, model):\n        pass\n\n    @abstractmethod\n    def get_config(self):\n        pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:20.558542Z","iopub.execute_input":"2026-01-08T03:06:20.558842Z","iopub.status.idle":"2026-01-08T03:06:20.572709Z","shell.execute_reply.started":"2026-01-08T03:06:20.558809Z","shell.execute_reply":"2026-01-08T03:06:20.571898Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nclass LoRAStrategy(FineTuningStrategy):\n\n    def __init__(\n        self,\n        r=16,\n        lora_alpha=32,\n        lora_dropout=0.05\n    ):\n        self.config =  LoraConfig(\n    r=8,                      # тЖУ from 16\n    lora_alpha=16,            # тЖУ from 32\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n    def apply(self, model):\n        return get_peft_model(model, self.config)\n\n    def get_config(self):\n        return self.config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:20.573590Z","iopub.execute_input":"2026-01-08T03:06:20.573808Z","iopub.status.idle":"2026-01-08T03:06:36.106880Z","shell.execute_reply.started":"2026-01-08T03:06:20.573786Z","shell.execute_reply":"2026-01-08T03:06:36.106297Z"}},"outputs":[{"name":"stderr","text":"2026-01-08 03:06:22.925922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767841583.109617      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767841583.168536      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767841583.668600      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767841583.668697      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767841583.668701      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767841583.668704      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:36.107767Z","iopub.execute_input":"2026-01-08T03:06:36.108393Z","iopub.status.idle":"2026-01-08T03:06:36.112292Z","shell.execute_reply.started":"2026-01-08T03:06:36.108364Z","shell.execute_reply":"2026-01-08T03:06:36.111671Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# bnb_config = BitsAndBytesConfig(\n#     load_in_8bit=True,\n#     llm_int8_threshold=6.0,\n#     llm_int8_has_fp16_weight=False\n# )\nbnb_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n    llm_int8_threshold=6.0,\n    llm_int8_has_fp16_weight=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:36.113069Z","iopub.execute_input":"2026-01-08T03:06:36.113399Z","iopub.status.idle":"2026-01-08T03:06:36.126619Z","shell.execute_reply.started":"2026-01-08T03:06:36.113362Z","shell.execute_reply":"2026-01-08T03:06:36.126028Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"**Step 6**","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:36.127498Z","iopub.execute_input":"2026-01-08T03:06:36.127752Z","iopub.status.idle":"2026-01-08T03:06:36.186834Z","shell.execute_reply.started":"2026-01-08T03:06:36.127729Z","shell.execute_reply":"2026-01-08T03:06:36.186152Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./llama-bengali-empathetic\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=1,   # ЁЯФС\n    learning_rate=2e-4,\n    max_steps=2500,                   # ЁЯФС\n    fp16=True,                       # ЁЯФС\n    logging_steps=25,\n    eval_strategy=\"no\",\n    save_strategy=\"no\",\n    report_to=\"none\",\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:36.187592Z","iopub.execute_input":"2026-01-08T03:06:36.187785Z","iopub.status.idle":"2026-01-08T03:06:36.410868Z","shell.execute_reply.started":"2026-01-08T03:06:36.187764Z","shell.execute_reply":"2026-01-08T03:06:36.410272Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    # quantization_config=bnb_config,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    low_cpu_mem_usage=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:06:36.413815Z","iopub.execute_input":"2026-01-08T03:06:36.414070Z","iopub.status.idle":"2026-01-08T03:07:21.078064Z","shell.execute_reply.started":"2026-01-08T03:06:36.414045Z","shell.execute_reply":"2026-01-08T03:07:21.077209Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d98b91818a47cbbd217e423458a88a"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0b715a6d774c7ab449734ea09f24ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48d3a02d9c54a4eaad0720b41a2bee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be22cc9c54824230a8177eff5eececdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ddd970bdc1451baa412bbe49c235f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edeff44e4ee548958a0c32066222321d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91afefa1d1b746008f5527d841a77612"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\nmodel.config.use_cache = False\n\nfrom peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    r=8,                      # тЖУ from 16\n    lora_alpha=16,            # тЖУ from 32\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:21.079275Z","iopub.execute_input":"2026-01-08T03:07:21.079621Z","iopub.status.idle":"2026-01-08T03:07:21.475948Z","shell.execute_reply.started":"2026-01-08T03:07:21.079578Z","shell.execute_reply":"2026-01-08T03:07:21.474419Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:21.477228Z","iopub.execute_input":"2026-01-08T03:07:21.477581Z","iopub.status.idle":"2026-01-08T03:07:39.715649Z","shell.execute_reply.started":"2026-01-08T03:07:21.477539Z","shell.execute_reply":"2026-01-08T03:07:39.714961Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/3538933475.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:39.716528Z","iopub.execute_input":"2026-01-08T03:07:39.716861Z","iopub.status.idle":"2026-01-08T03:07:39.721583Z","shell.execute_reply.started":"2026-01-08T03:07:39.716832Z","shell.execute_reply":"2026-01-08T03:07:39.720502Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# 1. Prepare model for 8-bit training\nmodel = prepare_model_for_kbit_training(model)\n\n# 2. Enable gradient checkpointing input grads\nmodel.enable_input_require_grads()\n\n# 3. Disable cache (already done, but keep it here)\nmodel.config.use_cache = False\n\n# 4. Apply LoRA\nlora_strategy = LoRAStrategy()\nmodel = lora_strategy.apply(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:39.722654Z","iopub.execute_input":"2026-01-08T03:07:39.722954Z","iopub.status.idle":"2026-01-08T03:07:39.962706Z","shell.execute_reply.started":"2026-01-08T03:07:39.722922Z","shell.execute_reply":"2026-01-08T03:07:39.961857Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:39.963739Z","iopub.execute_input":"2026-01-08T03:07:39.964045Z","iopub.status.idle":"2026-01-08T03:07:39.969601Z","shell.execute_reply.started":"2026-01-08T03:07:39.964018Z","shell.execute_reply":"2026-01-08T03:07:39.968997Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:07:39.970549Z","iopub.execute_input":"2026-01-08T03:07:39.970999Z","iopub.status.idle":"2026-01-08T03:52:10.108682Z","shell.execute_reply.started":"2026-01-08T03:07:39.970945Z","shell.execute_reply":"2026-01-08T03:52:10.107923Z"}},"outputs":[{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 44:28, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.417200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.927400</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.943600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.863700</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.809500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.783900</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.816800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.826500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.764500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.800500</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.759600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.767500</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.778000</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.740900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.791500</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.740000</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.768300</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.709500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.751800</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.743000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.768300</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.745500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.696600</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.782200</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.709300</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.704300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.681400</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.705100</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.735700</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.725100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.699500</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.742700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.685800</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.710100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.723600</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.702000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.684900</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.714300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.753600</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.684900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.703000</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>0.652200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.648600</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>0.676400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.711000</td>\n    </tr>\n    <tr>\n      <td>1175</td>\n      <td>0.706600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.699600</td>\n    </tr>\n    <tr>\n      <td>1225</td>\n      <td>0.709900</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.714700</td>\n    </tr>\n    <tr>\n      <td>1275</td>\n      <td>0.662700</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.724300</td>\n    </tr>\n    <tr>\n      <td>1325</td>\n      <td>0.656200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.697000</td>\n    </tr>\n    <tr>\n      <td>1375</td>\n      <td>0.683000</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.684800</td>\n    </tr>\n    <tr>\n      <td>1425</td>\n      <td>0.695700</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.679500</td>\n    </tr>\n    <tr>\n      <td>1475</td>\n      <td>0.678600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.665300</td>\n    </tr>\n    <tr>\n      <td>1525</td>\n      <td>0.654600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.676300</td>\n    </tr>\n    <tr>\n      <td>1575</td>\n      <td>0.654100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.683800</td>\n    </tr>\n    <tr>\n      <td>1625</td>\n      <td>0.711800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.637900</td>\n    </tr>\n    <tr>\n      <td>1675</td>\n      <td>0.718200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.643300</td>\n    </tr>\n    <tr>\n      <td>1725</td>\n      <td>0.693900</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.660300</td>\n    </tr>\n    <tr>\n      <td>1775</td>\n      <td>0.685700</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.684900</td>\n    </tr>\n    <tr>\n      <td>1825</td>\n      <td>0.702100</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.681600</td>\n    </tr>\n    <tr>\n      <td>1875</td>\n      <td>0.644700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.649200</td>\n    </tr>\n    <tr>\n      <td>1925</td>\n      <td>0.611000</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.639400</td>\n    </tr>\n    <tr>\n      <td>1975</td>\n      <td>0.608200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.699500</td>\n    </tr>\n    <tr>\n      <td>2025</td>\n      <td>0.699500</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.610600</td>\n    </tr>\n    <tr>\n      <td>2075</td>\n      <td>0.599200</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.687100</td>\n    </tr>\n    <tr>\n      <td>2125</td>\n      <td>0.662900</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.660100</td>\n    </tr>\n    <tr>\n      <td>2175</td>\n      <td>0.662300</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.697000</td>\n    </tr>\n    <tr>\n      <td>2225</td>\n      <td>0.687100</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.617500</td>\n    </tr>\n    <tr>\n      <td>2275</td>\n      <td>0.694100</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.659300</td>\n    </tr>\n    <tr>\n      <td>2325</td>\n      <td>0.594300</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.664600</td>\n    </tr>\n    <tr>\n      <td>2375</td>\n      <td>0.623000</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.633300</td>\n    </tr>\n    <tr>\n      <td>2425</td>\n      <td>0.655200</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.675400</td>\n    </tr>\n    <tr>\n      <td>2475</td>\n      <td>0.634300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.638600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2500, training_loss=0.7110343650817871, metrics={'train_runtime': 2669.7065, 'train_samples_per_second': 0.936, 'train_steps_per_second': 0.936, 'total_flos': 2.40770392971264e+16, 'train_loss': 0.7110343650817871, 'epoch': 0.07269766495100177})"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"**Deliverables**\n 1. Preprocessing notebook/script.\n 2. Fine-tuning notebook/script\n 3. Evaluation notebook/script\n 4. Sample Bengali responses\n 5. Metrics table\n 6. Analysis summary\n 7. Documentation (strategy, challenges, solutions)","metadata":{}},{"cell_type":"markdown","source":"**Generate Bengali Empathetic Responses**","metadata":{}},{"cell_type":"code","source":"model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:52:10.110314Z","iopub.execute_input":"2026-01-08T03:52:10.110593Z","iopub.status.idle":"2026-01-08T03:52:10.123060Z","shell.execute_reply.started":"2026-01-08T03:52:10.110569Z","shell.execute_reply":"2026-01-08T03:52:10.122375Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PeftModelForCausalLM(\n      (base_model): LoraModel(\n        (model): LlamaForCausalLM(\n          (model): LlamaModel(\n            (embed_tokens): Embedding(32000, 4096)\n            (layers): ModuleList(\n              (0-31): 32 x LlamaDecoderLayer(\n                (self_attn): LlamaAttention(\n                  (q_proj): lora.Linear(\n                    (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                  (v_proj): lora.Linear(\n                    (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                )\n                (mlp): LlamaMLP(\n                  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n                  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n                  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n                  (act_fn): SiLUActivation()\n                )\n                (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n                (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n              )\n            )\n            (norm): LlamaRMSNorm((4096,), eps=1e-05)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"prompt = \"\"\"### Instruction:\nSolve the following calculation and explain briefly.\n\n### User:\n125 ├Ч 24 + 18 ржХржд?\n\n### Assistant:\n\"\"\"\n\n\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    output = model.generate(\n        **inputs,\n        max_new_tokens=150,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9\n    )\n\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:06:00.796801Z","iopub.execute_input":"2026-01-08T04:06:00.797549Z","iopub.status.idle":"2026-01-08T04:06:17.356824Z","shell.execute_reply.started":"2026-01-08T04:06:00.797518Z","shell.execute_reply":"2026-01-08T04:06:17.356069Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nSolve the following calculation and explain briefly.\n\n### User:\n125 ├Ч 24 + 18 ржХржд?\n\n### Assistant:\nржЖржкржирж┐ ржПржЦржи ржПржЯрж╛ ржХрж┐ ржЪрж╛ржХрж░рж┐ ржЖржЫрзЗ? ржЖржкржирж┐ рж╕ржм ржзрж░ржирзЗрж░ ржХрж╛ржЬ ржХрж┐ ржЖржЫрзЗ? ржПржЯрж╛ ржЖржкржирж╛рж░ ржЬржирзНржп ржПржХржЯрж┐ ржЪрж╛ржХрж░рж┐ ржирж╛ ржХрж┐? ржЖржкржирж┐ ржХрж┐ ржПржЯрж╛ ржЖржкржирж╛рж░ рж╕рж╛\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"model.save_pretrained(\"./lora-bengali-empathetic\")\ntokenizer.save_pretrained(\"./lora-bengali-empathetic\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T03:52:27.667584Z","iopub.execute_input":"2026-01-08T03:52:27.667906Z","iopub.status.idle":"2026-01-08T03:52:27.812592Z","shell.execute_reply.started":"2026-01-08T03:52:27.667867Z","shell.execute_reply":"2026-01-08T03:52:27.811637Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"('./lora-bengali-empathetic/tokenizer_config.json',\n './lora-bengali-empathetic/special_tokens_map.json',\n './lora-bengali-empathetic/chat_template.jinja',\n './lora-bengali-empathetic/tokenizer.model',\n './lora-bengali-empathetic/added_tokens.json',\n './lora-bengali-empathetic/tokenizer.json')"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"**Metrics Table**","metadata":{}},{"cell_type":"code","source":"# !pip install evaluate nltk rouge-score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:09:54.788499Z","iopub.execute_input":"2026-01-08T04:09:54.789084Z","iopub.status.idle":"2026-01-08T04:10:01.948376Z","shell.execute_reply.started":"2026-01-08T04:09:54.789049Z","shell.execute_reply":"2026-01-08T04:10:01.947627Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c819849073f430fbea9e8258947093bdfb4dceb1c8812a4b3a3c49a7c40669e2\n  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score, evaluate\nSuccessfully installed evaluate-0.4.6 rouge-score-0.1.2\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def extract_prompt_and_answer(text):\n    prompt, answer = text.split(\"### Assistant:\")\n    return prompt + \"### Assistant:\", answer.strip()\n\nval_prompts = []\nval_references = []\n\nfor t in val_df[\"text\"].tolist():\n    p, a = extract_prompt_and_answer(t)\n    val_prompts.append(p)\n    val_references.append(a)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:10:06.924911Z","iopub.execute_input":"2026-01-08T04:10:06.925275Z","iopub.status.idle":"2026-01-08T04:10:06.943117Z","shell.execute_reply.started":"2026-01-08T04:10:06.925236Z","shell.execute_reply":"2026-01-08T04:10:06.942466Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"import torch\n\ndef generate_response(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=200,\n            temperature=0.7,\n            top_p=0.9,\n            do_sample=True,\n            eos_token_id=tokenizer.eos_token_id\n        )\n\n    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n    return decoded.split(\"### Assistant:\")[-1].strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:10:15.964187Z","iopub.execute_input":"2026-01-08T04:10:15.964489Z","iopub.status.idle":"2026-01-08T04:10:15.969759Z","shell.execute_reply.started":"2026-01-08T04:10:15.964460Z","shell.execute_reply":"2026-01-08T04:10:15.969010Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"N = 50  # recommended for Kaggle\npredictions = []\n\nfor i in range(N):\n    predictions.append(generate_response(val_prompts[i]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:10:25.302169Z","iopub.execute_input":"2026-01-08T04:10:25.302467Z","iopub.status.idle":"2026-01-08T04:29:05.183981Z","shell.execute_reply.started":"2026-01-08T04:10:25.302440Z","shell.execute_reply":"2026-01-08T04:29:05.183218Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"import evaluate\nimport nltk\nnltk.download(\"punkt\")\n\nbleu = evaluate.load(\"bleu\")\n\nbleu_score = bleu.compute(\n    predictions=predictions,\n    references=[[r] for r in val_references[:N]]\n)\n\nprint(\"BLEU:\", bleu_score[\"bleu\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:29:05.185393Z","iopub.execute_input":"2026-01-08T04:29:05.185663Z","iopub.status.idle":"2026-01-08T04:29:08.272647Z","shell.execute_reply.started":"2026-01-08T04:29:05.185638Z","shell.execute_reply":"2026-01-08T04:29:08.272075Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3a3289e67a468589a11ed519b614b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac7fe164d134fad945aebd536acaa30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e747185146574c94b501e7942a3060b0"}},"metadata":{}},{"name":"stdout","text":"BLEU: 0.0\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\n\nrouge_scores = rouge.compute(\n    predictions=predictions,\n    references=val_references[:N]\n)\n\nprint(rouge_scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:29:08.273529Z","iopub.execute_input":"2026-01-08T04:29:08.273834Z","iopub.status.idle":"2026-01-08T04:29:09.345917Z","shell.execute_reply.started":"2026-01-08T04:29:08.273798Z","shell.execute_reply":"2026-01-08T04:29:09.345380Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a622d4fa55e4fe186e5c4acc08ded06"}},"metadata":{}},{"name":"stdout","text":"{'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import math\nfrom torch.nn import CrossEntropyLoss\n\nlosses = []\n\nmodel.eval()\n\nfor batch in tokenized_val.select(range(100)):\n    input_ids = torch.tensor(batch[\"input_ids\"]).unsqueeze(0).to(model.device)\n\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids)\n        loss = outputs.loss\n\n    losses.append(loss.item())\n\nperplexity = math.exp(sum(losses) / len(losses))\nprint(\"Perplexity:\", perplexity)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:29:09.347736Z","iopub.execute_input":"2026-01-08T04:29:09.348031Z","iopub.status.idle":"2026-01-08T04:29:48.027327Z","shell.execute_reply.started":"2026-01-08T04:29:09.348006Z","shell.execute_reply":"2026-01-08T04:29:48.026532Z"}},"outputs":[{"name":"stdout","text":"Perplexity: 1.9473086080606958\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import pandas as pd\n\nmetrics_table = pd.DataFrame({\n    \"Metric\": [\"Perplexity\", \"BLEU\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"],\n    \"Score\": [\n        round(perplexity, 2),\n        round(bleu_score[\"bleu\"], 3),\n        round(rouge_scores[\"rouge1\"], 3),\n        round(rouge_scores[\"rouge2\"], 3),\n        round(rouge_scores[\"rougeL\"], 3)\n    ]\n})\n\nmetrics_table\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:29:48.028232Z","iopub.execute_input":"2026-01-08T04:29:48.028572Z","iopub.status.idle":"2026-01-08T04:29:48.039660Z","shell.execute_reply.started":"2026-01-08T04:29:48.028530Z","shell.execute_reply":"2026-01-08T04:29:48.039014Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"       Metric  Score\n0  Perplexity   1.95\n1        BLEU   0.00\n2     ROUGE-1   0.00\n3     ROUGE-2   0.00\n4     ROUGE-L   0.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perplexity</td>\n      <td>1.95</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BLEU</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ROUGE-1</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ROUGE-2</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ROUGE-L</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"metrics_table.to_csv(\"metrics_table.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T04:32:48.729701Z","iopub.execute_input":"2026-01-08T04:32:48.730321Z","iopub.status.idle":"2026-01-08T04:32:48.735386Z","shell.execute_reply.started":"2026-01-08T04:32:48.730288Z","shell.execute_reply":"2026-01-08T04:32:48.734530Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}